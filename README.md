

[Delong Chen (é™ˆå¾·é¾™)](https://chendelong.world/) is now a first-year Ph.D. student at the [Centre for Artificial Intelligence Research (CAiRE)](https://caire.hkust.edu.hk/) of Hong Kong University of Science and Technology (HKUST) under the supervision of [Prof. Pascale Fung](https://pascale.home.ece.ust.hk/about.html). 

Before that, he received the bachelor degree in computer science from Hohai University (æ²³æµ·å¤§å­¦) in 2021, where he was advised by [Prof. Fan Liu](https://multimodality.group/author/%E5%88%98%E5%87%A1/) (åˆ˜å‡¡) at the [Artificial Intelligence of Multi-modality Group (AIM Group)](https://multimodality.group/). 

Afterward, he took two gap years (2021-2023) doing internships at [MEGVII Research](https://en.megvii.com), [MSRA](https://www.microsoft.com/en-us/research/lab/microsoft-research-asia/) and [Xiaobing.AI](https://www.xiaoice.com/), respectively working on vision-language pretraining, vision-language for embodied AI, and multimodal LLMs. 

<img align="right" src="https://github-readme-stats.vercel.app/api?username=ChenDelong1999" />

ðŸ’¡ **Research interests**
  - Multi-modal LLMs, vision language learning
  - Self-supervised visual representation learning
  - Music information retrieval

